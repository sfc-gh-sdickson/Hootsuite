{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\nst.image(\"Snowflake_Logo.svg\", width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hootsuite Intelligence Agent - ML Models\n\n**Training 3 Machine Learning Models for Social Media Intelligence**\n\nThis notebook trains 3 ML models for the Hootsuite Intelligence Agent:\n1. **CHURN_RISK_PREDICTOR** - Predicts customer churn risk (3 classes)\n2. **CAMPAIGN_ROI_PREDICTOR** - Predicts campaign ROI (3 classes)\n3. **TICKET_PRIORITY_CLASSIFIER** - Classifies ticket priority (4 classes)\n\n---\n\n## Prerequisites\n- Database: `HOOTSUITE_INTELLIGENCE`\n- Schema: `ML_MODELS`\n- Feature views created (V_CHURN_RISK_FEATURES, V_CAMPAIGN_ROI_FEATURES, V_TICKET_PRIORITY_FEATURES)\n- Packages: `snowflake-ml-python`, `scikit-learn`, `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\nprint(os.listdir('.'))  # Lists all files in current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\nfrom snowflake.snowpark import Session\nfrom snowflake.ml.modeling.ensemble import RandomForestClassifier\nfrom snowflake.ml.modeling.linear_model import LogisticRegression\nfrom snowflake.ml.modeling.preprocessing import OneHotEncoder, StandardScaler\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.registry import Registry\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nprint(\"\u2705 Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current session\nsession = Session.builder.getOrCreate()\n\n# Set context\nsession.use_database(\"HOOTSUITE_INTELLIGENCE\")\nsession.use_schema(\"ML_MODELS\")\nsession.use_warehouse(\"HOOTSUITE_WH\")\n\nprint(\"\u2705 Session configured\")\nprint(f\"Database: {session.get_current_database()}\")\nprint(f\"Schema: {session.get_current_schema()}\")\nprint(f\"Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Registry\nregistry = Registry(\n    session=session,\n    database_name=\"HOOTSUITE_INTELLIGENCE\",\n    schema_name=\"ML_MODELS\"\n)\n\nprint(\"\u2705 Model Registry initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Model 1: Churn Risk Predictor\n\n**Objective**: Predict customer churn risk  \n**Labels**: 0=Low Risk, 1=Medium Risk, 2=High Risk  \n**Algorithm**: Random Forest Classifier  \n**Features**: Plan type, industry, employee count, revenue, tenure, tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load churn feature data\nchurn_df = session.table(\"HOOTSUITE_INTELLIGENCE.ANALYTICS.V_CHURN_RISK_FEATURES\")\n\nprint(f\"\u2705 Loaded {churn_df.count()} records for churn prediction\")\nchurn_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\ntrain_churn, test_churn = churn_df.random_split([0.8, 0.2], seed=42)\n\n# Drop ID columns not needed for training\ntrain_churn = train_churn.drop(\"CUSTOMER_ID\")\ntest_churn = test_churn.drop(\"CUSTOMER_ID\")\n\nprint(f\"Training set: {train_churn.count()} records\")\nprint(f\"Test set: {test_churn.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAST churn prediction pipeline - optimized for <10s execution\n# Using simpler model: fewer trees, shallow depth, no scaling\nchurn_pipeline = Pipeline([\n    (\"Encoder\", OneHotEncoder(\n        input_cols=[\"PLAN_TYPE\", \"INDUSTRY\"],\n        output_cols=[\"PLAN_TYPE_ENC\", \"INDUSTRY_ENC\"],\n        drop_input_cols=True,\n        handle_unknown=\"ignore\"\n    )),\n    (\"Classifier\", RandomForestClassifier(\n        label_cols=[\"CHURN_RISK_LABEL\"],\n        output_cols=[\"PREDICTED_RISK\"],\n        n_estimators=3,\n        max_depth=3,\n        random_state=42\n    ))\n])\n\nprint(\"\u2705 Churn prediction pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the churn prediction model\nprint(\"Training churn prediction model...\")\nchurn_pipeline.fit(train_churn)\nprint(\"\u2705 Churn prediction model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\ntest_predictions = churn_pipeline.predict(test_churn)\ntest_results = test_predictions.select(\"CHURN_RISK_LABEL\", \"PREDICTED_RISK\").to_pandas()\n\nfrom sklearn.metrics import accuracy_score, classification_report\naccuracy = accuracy_score(test_results['CHURN_RISK_LABEL'], test_results['PREDICTED_RISK'])\n\nprint(f\"Test Accuracy: {accuracy:.3f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(\n    test_results['CHURN_RISK_LABEL'], \n    test_results['PREDICTED_RISK']\n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model in Model Registry\n# Drop label column from sample data - model signature should only include features\nsample_data = train_churn.drop(\"CHURN_RISK_LABEL\").limit(100)\n\nregistry.log_model(\n    model=churn_pipeline,\n    model_name=\"CHURN_RISK_PREDICTOR\",\n    target_platforms=['WAREHOUSE'],\n    sample_input_data=sample_data,\n    comment=\"Predicts customer churn risk with 3 risk levels (Low/Medium/High)\"\n)\n\nprint(\"\u2705 CHURN_RISK_PREDICTOR registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Model 2: Campaign ROI Predictor\n\n**Objective**: Predict campaign ROI likelihood  \n**Labels**: 0=Low ROI, 1=Medium ROI, 2=High ROI  \n**Algorithm**: Logistic Regression  \n**Features**: Objective, budget, duration, posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load campaign ROI feature data\nroi_df = session.table(\"HOOTSUITE_INTELLIGENCE.ANALYTICS.V_CAMPAIGN_ROI_FEATURES\")\n\nprint(f\"\u2705 Loaded {roi_df.count()} records for ROI prediction\")\nroi_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\ntrain_roi, test_roi = roi_df.random_split([0.8, 0.2], seed=42)\n\ntrain_roi = train_roi.drop(\"CAMPAIGN_ID\")\ntest_roi = test_roi.drop(\"CAMPAIGN_ID\")\n\nprint(f\"Training set: {train_roi.count()} records\")\nprint(f\"Test set: {test_roi.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAST ROI prediction pipeline - optimized for <10s execution\n# Using LogisticRegression with fewer iterations, no scaling\nroi_pipeline = Pipeline([\n    (\"Encoder\", OneHotEncoder(\n        input_cols=[\"OBJECTIVE\"],\n        output_cols=[\"OBJECTIVE_ENC\"],\n        drop_input_cols=True,\n        handle_unknown=\"ignore\"\n    )),\n    (\"Classifier\", LogisticRegression(\n        label_cols=[\"ROI_LABEL\"],\n        output_cols=[\"PREDICTED_ROI\"],\n        max_iter=100\n    ))\n])\n\nprint(\"\u2705 ROI prediction pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ROI prediction model\nprint(\"Training ROI prediction model...\")\nroi_pipeline.fit(train_roi)\nprint(\"\u2705 ROI prediction model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\ntest_predictions = roi_pipeline.predict(test_roi)\ntest_results = test_predictions.select(\"ROI_LABEL\", \"PREDICTED_ROI\").to_pandas()\n\naccuracy = accuracy_score(test_results['ROI_LABEL'], test_results['PREDICTED_ROI'])\n\nprint(f\"Test Accuracy: {accuracy:.3f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(\n    test_results['ROI_LABEL'], \n    test_results['PREDICTED_ROI'],\n    target_names=['Low ROI', 'Medium ROI', 'High ROI']\n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model\n# Drop label column from sample data - model signature should only include features\nsample_data = train_roi.drop(\"ROI_LABEL\").limit(100)\n\nregistry.log_model(\n    model=roi_pipeline,\n    model_name=\"CAMPAIGN_ROI_PREDICTOR\",\n    target_platforms=['WAREHOUSE'],\n    sample_input_data=sample_data,\n    comment=\"Predicts campaign ROI with 3 outcomes (Low/Medium/High)\"\n)\n\nprint(\"\u2705 CAMPAIGN_ROI_PREDICTOR registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Model 3: Ticket Priority Classifier\n\n**Objective**: Classify support ticket priority  \n**Labels**: 0=Low, 1=Medium, 2=High, 3=Urgent  \n**Algorithm**: Random Forest Classifier  \n**Features**: Category, issue summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ticket priority feature data\nticket_df = session.table(\"HOOTSUITE_INTELLIGENCE.ANALYTICS.V_TICKET_PRIORITY_FEATURES\")\n\nprint(f\"\u2705 Loaded {ticket_df.count()} records for ticket priority classification\")\nticket_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\ntrain_ticket, test_ticket = ticket_df.random_split([0.8, 0.2], seed=42)\n\ntrain_ticket = train_ticket.drop(\"TICKET_ID\")\ntest_ticket = test_ticket.drop(\"TICKET_ID\")\n\nprint(f\"Training set: {train_ticket.count()} records\")\nprint(f\"Test set: {test_ticket.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAST ticket priority pipeline - optimized for <10s execution\n# Using simpler RandomForest: fewer trees, shallow depth, no scaling\nticket_pipeline = Pipeline([\n    (\"Encoder\", OneHotEncoder(\n        input_cols=[\"CATEGORY\"],\n        output_cols=[\"CATEGORY_ENC\"],\n        drop_input_cols=True,\n        handle_unknown=\"ignore\"\n    )),\n    (\"Classifier\", RandomForestClassifier(\n        label_cols=[\"PRIORITY_LABEL\"],\n        output_cols=[\"PREDICTED_PRIORITY\"],\n        n_estimators=3,\n        max_depth=3,\n        random_state=42\n    ))\n])\n\nprint(\"\u2705 Ticket priority pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ticket priority model\nprint(\"Training ticket priority model...\")\nticket_pipeline.fit(train_ticket)\nprint(\"\u2705 Ticket priority model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\ntest_predictions = ticket_pipeline.predict(test_ticket)\ntest_results = test_predictions.select(\"PRIORITY_LABEL\", \"PREDICTED_PRIORITY\").to_pandas()\n\naccuracy = accuracy_score(test_results['PRIORITY_LABEL'], test_results['PREDICTED_PRIORITY'])\n\nprint(f\"Test Accuracy: {accuracy:.3f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(\n    test_results['PRIORITY_LABEL'], \n    test_results['PREDICTED_PRIORITY'],\n    target_names=['Low', 'Medium', 'High', 'Urgent']\n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model\n# Drop label column from sample data - model signature should only include features\nsample_data = train_ticket.drop(\"PRIORITY_LABEL\").limit(100)\n\nregistry.log_model(\n    model=ticket_pipeline,\n    model_name=\"TICKET_PRIORITY_CLASSIFIER\",\n    target_platforms=['WAREHOUSE'],\n    sample_input_data=sample_data,\n    comment=\"Classifies ticket priority with 4 levels (Low/Medium/High/Urgent)\"\n)\n\nprint(\"\u2705 TICKET_PRIORITY_CLASSIFIER registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Summary and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all registered models\nmodels = session.sql(\"SHOW MODELS IN SCHEMA ML_MODELS\").collect()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"REGISTERED MODELS\")\nprint(\"=\"*80)\nfor model in models:\n    print(f\"\u2705 {model['name']}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"MODEL TRAINING COMPLETE\")\nprint(\"=\"*80)\nprint(\"\\n3 ML models successfully trained and registered:\")\nprint(\"1. CHURN_RISK_PREDICTOR - Predicts churn risk (3 classes)\")\nprint(\"2. CAMPAIGN_ROI_PREDICTOR - Predicts ROI (3 classes)\")\nprint(\"3. TICKET_PRIORITY_CLASSIFIER - Classifies priority (4 classes)\")\nprint(\"\\nNext steps:\")\nprint(\"1. Run hootsuite_07_ml_model_functions.sql to create SQL procedures\")\nprint(\"2. Run hootsuite_08_intelligence_agent.sql to configure agent\")\nprint(\"3. Test agent with sample questions from hootsuite_questions.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}